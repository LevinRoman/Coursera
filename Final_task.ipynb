{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with NaN: Index(['first_blood_time', 'first_blood_team', 'first_blood_player1',\n",
      "       'first_blood_player2', 'radiant_bottle_time', 'radiant_courier_time',\n",
      "       'radiant_flying_courier_time', 'radiant_first_ward_time',\n",
      "       'dire_bottle_time', 'dire_courier_time', 'dire_flying_courier_time',\n",
      "       'dire_first_ward_time'],\n",
      "      dtype='object') 12\n",
      "[mean: 0.66439, std: 0.00490, params: {'n_estimators': 10}, mean: 0.68285, std: 0.00501, params: {'n_estimators': 20}, mean: 0.68950, std: 0.00453, params: {'n_estimators': 30}, mean: 0.69413, std: 0.00433, params: {'n_estimators': 40}, mean: 0.69745, std: 0.00391, params: {'n_estimators': 50}, mean: 0.70633, std: 0.00359, params: {'n_estimators': 100}]\n",
      "Time elapsed: 0:24:09.175888\n"
     ]
    }
   ],
   "source": [
    "#Подход 1. Градиентный бустинг. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "\n",
    "aim = features['radiant_win']\n",
    "#Задание 1. Удаляем признаки:\n",
    "features = features.drop(['radiant_win', 'duration','tower_status_radiant','tower_status_dire','barracks_status_radiant','barracks_status_dire'], axis = 1)\n",
    "#Задание 2. Ищем признаки с пропусками:\n",
    "features_with_nans = np.nonzero(features.count(axis = 0) < 97230)\n",
    "print(\"Features with NaN:\", features.axes[1][features_with_nans], len(features.axes[1][features_with_nans]))\n",
    "\n",
    "#Рассмотрим признаки first_blood_time и radiant_first_ward_time. Оба они имеют пропуски, так как соответствующие события могли\n",
    "#не случиться за первые пять минут в каких-то матчах. Например, не было \"первой крови\" или установки наблюдателя. Может быть, \n",
    "#наблюдатель вообще не был установлен за всю игру.\n",
    "\n",
    "#Задание 3. Заполняем пропуски:\n",
    "features = features.fillna(value = 0)\n",
    "#Задание 4: Целевую переменную содержит столбец 'radiant_win'. Его мы в самом начале, перед удалением сохранили в aim\n",
    "#Задание 5. Обучаем Градиентный бустинг и смотрим на качество кросс-валидации при разном количестве деревьев:\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "grid = {'n_estimators': [10,20,30,40,50,100]} #функция AUC_ROC и predict_proba используются при gridsearch. Они вызываются внутри\n",
    "cr_v = KFold(aim.size, n_folds = 5, shuffle = True, random_state = 241)\n",
    "clf = GradientBoostingClassifier(random_state = 241)\n",
    "gs = GridSearchCV(clf, grid, scoring = 'roc_auc', cv = cr_v)\n",
    "gs.fit(features, aim)\n",
    "print(gs.grid_scores_)\n",
    "\n",
    "\n",
    "print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "#Экспериментально видим, что с увеличением количества деревьев растет качество. То есть качество продолжит расти, отимум не достигнут.\n",
    "#Лучшее качество получилось на 100 деревьях. Обучение 10,20,30,40,50 и 100 деревьев и кросс валидация заняли 24 минуты. \n",
    "#На 30 деревьях градиентный бустинг обучался около 3-х минут. Довольно долго, даже если учесть, что компьютер совсем не мощный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with NaN: Index(['first_blood_time', 'first_blood_team', 'first_blood_player1',\n",
      "       'first_blood_player2', 'radiant_bottle_time', 'radiant_courier_time',\n",
      "       'radiant_flying_courier_time', 'radiant_first_ward_time',\n",
      "       'dire_bottle_time', 'dire_courier_time', 'dire_flying_courier_time',\n",
      "       'dire_first_ward_time'],\n",
      "      dtype='object') 12\n",
      "0.01 0.716341465365 [mean: 0.69512, std: 0.00263, params: {'C': 1.0000000000000001e-05}, mean: 0.71125, std: 0.00271, params: {'C': 0.0001}, mean: 0.71618, std: 0.00275, params: {'C': 0.001}, mean: 0.71634, std: 0.00281, params: {'C': 0.01}, mean: 0.71631, std: 0.00283, params: {'C': 0.10000000000000001}, mean: 0.71631, std: 0.00283, params: {'C': 1.0}, mean: 0.71631, std: 0.00283, params: {'C': 10.0}, mean: 0.71631, std: 0.00283, params: {'C': 100.0}, mean: 0.71631, std: 0.00283, params: {'C': 1000.0}, mean: 0.71631, std: 0.00283, params: {'C': 10000.0}, mean: 0.71631, std: 0.00283, params: {'C': 100000.0}]\n",
      "Time elapsed: 0:03:24.162677\n"
     ]
    }
   ],
   "source": [
    "#Подход 2. Логистическая регрессия.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "\n",
    "aim = features['radiant_win']\n",
    "\n",
    "features = features.drop(['radiant_win', 'duration','tower_status_radiant','tower_status_dire','barracks_status_radiant','barracks_status_dire'], axis = 1)\n",
    "\n",
    "features_with_nans = np.nonzero(features.count(axis = 0) < 97230)\n",
    "print(\"Features with NaN:\", features.axes[1][features_with_nans], len(features.axes[1][features_with_nans]))\n",
    "\n",
    "features = features.fillna(value = 0)\n",
    "#Задание 1. Отмасштабируем признаки и обучим логистическую регрессию. Оптимальный параметр получился С=0.01. \n",
    "#Мы также достигли лучшего качества за ощутимо меньшее время, чем при бустинге.\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "import time\n",
    "import datetime\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "cr_v = KFold(aim.size, n_folds = 5, shuffle = True, random_state = 241)\n",
    "clf = LogisticRegression(random_state = 241)\n",
    "gs = GridSearchCV(clf, grid, scoring = 'roc_auc', cv = cr_v)\n",
    "gs.fit(features_scaled, aim)\n",
    "print(gs.best_params_['C'], gs.best_score_, gs.grid_scores_)\n",
    "\n",
    "\n",
    "print ('Time elapsed:', datetime.datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.716400950653 [mean: 0.69506, std: 0.00265, params: {'C': 1.0000000000000001e-05}, mean: 0.71125, std: 0.00276, params: {'C': 0.0001}, mean: 0.71624, std: 0.00280, params: {'C': 0.001}, mean: 0.71640, std: 0.00285, params: {'C': 0.01}, mean: 0.71637, std: 0.00286, params: {'C': 0.10000000000000001}, mean: 0.71637, std: 0.00286, params: {'C': 1.0}, mean: 0.71637, std: 0.00286, params: {'C': 10.0}, mean: 0.71637, std: 0.00286, params: {'C': 100.0}, mean: 0.71637, std: 0.00286, params: {'C': 1000.0}, mean: 0.71637, std: 0.00286, params: {'C': 10000.0}, mean: 0.71637, std: 0.00286, params: {'C': 100000.0}]\n"
     ]
    }
   ],
   "source": [
    "#Задание 2. Удалим категорные признаки из выборки. Снова обучим Логистическую регрессию.\n",
    "categorial_features = ['lobby_type'] + ['r' + str(i) + '_hero' for i in range(1,6)] + ['d' + str(i) + '_hero' for i in range(1,6)]\n",
    "non_cat_feat = features.drop(categorial_features, axis = 1)\n",
    "scaler_two = StandardScaler()\n",
    "non_cat_feat_scaled = scaler_two.fit_transform(non_cat_feat)\n",
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "cr_v = KFold(aim.size, n_folds = 5, shuffle = True, random_state = 241)\n",
    "clf = LogisticRegression(random_state = 241)\n",
    "gs = GridSearchCV(clf, grid, scoring = 'roc_auc', cv = cr_v)\n",
    "gs.fit(non_cat_feat_scaled, aim)\n",
    "print(gs.best_params_['C'], gs.best_score_, gs.grid_scores_)\n",
    "#Качество немного улучшилось - в 4 знаке после запятой. Улучшилось - потому что категорные признаки, использованные как числовые,\n",
    "#могут ослабить результат. С другой стороны, видимо, они имели небольшой вес, поэтому их удаление почти не повлияло на качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 109 110 112]\n"
     ]
    }
   ],
   "source": [
    "#Задание 3. Выясним количество идентификаторов героев в игре.\n",
    "heroes = [ind for ind in features.columns if 'hero' in ind]\n",
    "unique_heroes = np.unique(features[heroes])\n",
    "print(len(unique_heroes), unique_heroes) #То есть уникальных героев у нас 108, нескольких не хватает, т.к. максимальный номер 112.\n",
    "#Но мешок слов в следующем задании будем составлять, используя приведенный в задании код,возьмем там N=112, чтобы он корректно работал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with NaN: Index(['first_blood_time', 'first_blood_team', 'first_blood_player1',\n",
      "       'first_blood_player2', 'radiant_bottle_time', 'radiant_courier_time',\n",
      "       'radiant_flying_courier_time', 'radiant_first_ward_time',\n",
      "       'dire_bottle_time', 'dire_courier_time', 'dire_flying_courier_time',\n",
      "       'dire_first_ward_time'],\n",
      "      dtype='object') 12\n",
      "0.1 0.75193745059\n"
     ]
    }
   ],
   "source": [
    "#Пришлось еще раз скопировать код с началом программы, потому что из-за memory error перезапустилось ядро Ipython\n",
    "#Случайно еще раз напечатал признаки с пропусками\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "\n",
    "aim = features['radiant_win']\n",
    "\n",
    "features = features.drop(['radiant_win', 'duration','tower_status_radiant','tower_status_dire','barracks_status_radiant','barracks_status_dire'], axis = 1)\n",
    "\n",
    "features_with_nans = np.nonzero(features.count(axis = 0) < 97230)\n",
    "print(\"Features with NaN:\", features.axes[1][features_with_nans], len(features.axes[1][features_with_nans]))\n",
    "\n",
    "features = features.fillna(value = 0)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "categorial_features = ['lobby_type'] + ['r' + str(i) + '_hero' for i in range(1,6)] + ['d' + str(i) + '_hero' for i in range(1,6)]\n",
    "non_cat_feat = features.drop(categorial_features, axis = 1)\n",
    "scaler_two = StandardScaler()\n",
    "non_cat_feat_scaled = scaler_two.fit_transform(non_cat_feat)\n",
    "#Задание 4. Составление мешка слов.\n",
    "test = pd.read_csv('features_test.csv', index_col='match_id')\n",
    "test = test.fillna(0)\n",
    "non_cat_test = test.drop(categorial_features, axis = 1)\n",
    "non_cat_test_scaled = scaler_two.transform(non_cat_test)\n",
    "\n",
    "bag = np.zeros((features.shape[0], 112))\n",
    "#Берем N = 112, хотя уникальных игроков 108. У нас могут появиться лишние пропуски, но нули на алгоритм не влияют. \n",
    "#Не забываем параллельно создавать мешок слов и для тестовой выборки\n",
    "\n",
    "for i, match_id in enumerate(features.index):\n",
    "    for p in range(5):\n",
    "        bag[i, features.ix[match_id, 'r%d_hero' % (p+1)] - 1] = 1\n",
    "        bag[i, features.ix[match_id, 'd%d_hero' % (p+1)] - 1] = -1\n",
    "        \n",
    "bag_test = np.zeros((test.shape[0], 112))\n",
    "for i, match_id in enumerate(test.index):\n",
    "    for p in range(5):\n",
    "        bag_test[i, test.ix[match_id, 'r%d_hero' % (p+1)] - 1] = 1\n",
    "        bag_test[i, test.ix[match_id, 'd%d_hero' % (p+1)] - 1] = -1\n",
    "#Склеим теперь мешок слов и выборки с отмасштабированными весами. Мешок уже отмасштабирован, не будем его редактировать намеренно.\n",
    "train_result = np.hstack((non_cat_feat_scaled, bag))\n",
    "test_result = np.hstack((non_cat_test_scaled, bag_test))\n",
    "#Задание 5. Обучаем регрессию на новой выборке с учетом мешка слов.\n",
    "#Снова проводим обучение регрессии и подбор параметра С:\n",
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "cr_v = KFold(aim.size, n_folds = 5, shuffle = True, random_state = 241)\n",
    "clf = LogisticRegression(random_state = 241)\n",
    "gs = GridSearchCV(clf, grid, scoring = 'roc_auc', cv = cr_v)\n",
    "gs.fit(train_result, aim)\n",
    "print(gs.best_params_['C'], gs.best_score_)\n",
    "#Видим, что качество существенно выросло после использования мешка слов по сравнению с прошлым результатом. Этого удалось достичь,\n",
    "#так как мы извлекли информацию из категориальных признаков, которые до этого просто выбросили, информация о героях является\n",
    "#очень важной, исходя из здравого смысла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996371448815 0.00362855118457\n"
     ]
    }
   ],
   "source": [
    "#Задание 6. Теперь применим нашу модель к тестовой выборке, предскажем исходы матчей. Применять будем Логистическую регрессию с \n",
    "#мешком слов, так как она дала наилучший результат из всех вариантов.\n",
    "clf = LogisticRegression(C = 0.1, random_state = 241)\n",
    "clf.fit(train_result, aim)\n",
    "prediction = clf.predict_proba(test_result)\n",
    "print(np.amax(prediction), np.amin(prediction)) \n",
    "#Найдя наибольшее и наименьшее значение вероятностей, убеждаемся, что они не совпадают, то есть модель не обучилась константой.\n",
    "#Кроме того, наименьшее и наибольшее значение лежат на [0,1], значит и все значения - тоже. Что и требовалось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
